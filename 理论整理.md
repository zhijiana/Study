###### spark解决数据倾斜:

```sql
1.什么是数据倾斜: 数据计算时候,数据在各个节点分布不均匀.

数据倾斜在MR编程模型中很常见,是大量的相同key被分配到一个partition中,而其他partition被分配少量数据，就认为是数据倾斜.

数据倾斜的影响:
	造成"少数人累死,多数人闲死"的情况,违背了分布式计算的初衷.集群中一个或几个节点要承受巨大计算压力,其他节点计算完毕后要一致等待忙碌节点计算完成,拖累整体计算时间,直接导致计算效率低下.甚至出现最终executor被撑爆,OOM，

小结:
1.拖慢运行速度,计算效率低下.特别是对于几十亿到百亿的大表,倾斜情况下不夸张的情况,运行十几个小时不一定结束.
运行十几个小时也不一定结束.
2.撑破executor,OOM.大量数据涌入同一个task中的executor执行,直接结果是OOM,任务运行失败.

数据倾斜的解决:
1.数据倾斜的定位以及解决:
对于spark：
(1)倾斜key的定位方法:
	倾斜数据的三个情况:
	1.null值或一些无意义的信息.
	2.无效数据,大量重复的测试数据或是对结果影响不大的数据.
	3.有效数据,业务导致的正常数据分布.
(2)解决办法:
	1.将异常的key过滤出来单独处理,最后与正常数据的处理结果进行union操作;
	2.对所有key先添加随机值,进行操作后,去掉随机值,再继续后续操作.
	
	
对于spark-sql而言:
1.先尝试distribute by rand()操作,打乱数据分布.
2.通过配置开启倾斜key检测.


spark常见倾斜的场景以及解决:
spark的数据倾斜一般由shuffle时数据不均匀导致,一般会有三类算子产生shuffle: aggregation（group by）、join.
Aggregation:
建议打散key进行二次聚合.

数据膨胀:(join)

```

spark数据倾斜2:

```scala
数据倾斜危害:
	会造成部分任务处理的数据量过大,可能造成内存不足导致任务失败,进而引起整个应用失败.
	
	数据倾斜是怎么造成的:
		小量任务耗时远高于其他任务,从而使得整体耗时过大.
		当发生数据倾斜时,部分任务处理的数据量过大,可能造成内存不足使得任务失败,并进而使得整个应用失败.
	
	数据倾斜是怎么造成的?
	在spark中,同一个Stage的不同partition可以并性处理,而具有依赖关系的不同Stage之间是串行处理.假设某个Sparkjob分为stage0和stage1,且stage1依赖于stage0,那么stage0完全处理结束之前不会处理Stage1。
	stage下面包含若干个Task，spark任务的执行是按照最慢的task决定.
	

避免数据源的倾斜:
	1.读kafka数据;
	2.读取文件;
	数据源侧存在不可切分的文件,且文件内包含的数据量相差较大.

	
解决的方法1（自定义Partitoner）: 
	使用自定义的Partitoner实现类代替默认的HashPartitoner,尽量将不同的key均匀分配到不同Task中.

	
劣势: 
	适用场景有限,只能将不同key分散开,对于同一key对应数据集非常大的场景不适用.需要自己开发,不够灵敏.

解决方式2: 将Reduce side Join 转换成MapSideJoin

将小数据集拉取到Driver,然后通过Broadcast方案将小数据集中的数据广播到Executor。使用SQL之前,将Broadcast的阈值调整得足够大,从而1使用Broadcast生效,进而将reduce侧Join替换为Map侧join。

// 使用BroadCast实现Map侧join的方式: setBroadcastJoinThreshold,将Broadcast的阈值设置的足够大.
// 通过soark的BroadCast机制,将reduce侧join转换为Map侧join，避免数据倾斜从而完全消除shuffle带来的数据倾斜.
```

<img src="C:\Users\12085\AppData\Roaming\Typora\typora-user-images\image-20240322153359781.png" alt="image-20240322153359781" style="zoom:80%;" />

##### 为skew的key增加随机前/后缀：

```scala
适用于两张大表,无法使用Map端join,其中一个RDD有少数几个Key的数据量过大,另外一个RDD的key分布比较均匀.

原理:
	为数据量特别大的key增加随机前缀/后缀,使得原来key相同的数据变成key不同的数据,从而使倾斜的数据集分散到不同的task中,彻底解决数据倾斜问题.join另外一侧的数据中,与倾斜key对应的部分数据,与随机前缀做笛卡尔集,从而保证无论数据倾斜侧倾斜key如何加前缀,都能正常join.


总结:
适用场景:
两张表都比较大,无法使用Map Join,其中一个RDD有少数几个key的数据量过大,另外一个RDD的key分布比较均匀.

解决方案:
将有数据倾斜的RDD中倾斜key对应的数据集单独抽取出来加上随机前缀,另外一个RDD每条数据分别与随机前缀结合成为新的RDD(相当于将其数据增到原来的N倍,N即为随机前缀的总个数),
然后将二者Join并去掉前缀.然后将不包含倾斜key的剩余数据做join.最后将两次join的结果集通过union 合并,即可达到全部join结果.

劣势: 
如果倾斜key非常多,另一侧数据膨胀非常大,此方案不合适。并且此时对倾斜key和非倾斜key分开处理,需要扫描数据集两边,增加了开销.

大表随机添加N种随机前缀,小表扩大N倍.

如果出现数据倾斜的key比较多,上一种方式将这些大量的倾斜key拆分出来.此时更加适合直接对存在数据倾斜的数据集全部加上随机前缀,然后对另外一个不存在严重数据倾斜的数据集整体与随机前缀集做笛卡尔乘积.(即将数据量扩大N倍.)

```

###### 总结：

```
适用场景:
一个数据集存在的倾斜key比较多,另外一个数据集数据分布比较均匀.

优势:
对大部分场景适用。
劣势:
需要将一个数据集整体扩大N倍,会增加资源消耗.

```



##### spark和MapReduce：

```
MR只能做离线计算,如果实现复杂计算逻辑,一个MR搞不定,就需要将多个MR按先后顺序练成一串,一个MR计算完成后会将计算结果写入到HDFS中,
下一个MR将上一个MR的输出作为输入,这样需要频繁读写HDFS,网络IO和磁盘IO会成为性能瓶颈,导致效率低下.
```

<img src="C:\Users\12085\AppData\Roaming\Typora\typora-user-images\image-20240322195648214.png" alt="image-20240322195648214" style="zoom:67%;" />

​	spark主要用于大数据计算,Hadoop由于采用MR方式,多次反复读写磁盘，速度不如Spark,所以Spark和Hadoop根本差异是多个作业之间的数据通信问题: Spark多个作业之间数据通信是基于内存(Spark除了基于内存计算这一个计算快的原因,还有DAG有向无环图来切分任务的执行先后顺序)，而MR是基于磁盘的.Hadoop在后续用于大数据存储(HDFS、hive、Hbase)和资源调度(Yarn)

​	spark很可能会因为内存的限制,导致内存资源不足而job失败,MR其实是一个更好的选择.

<img src="C:\Users\12085\AppData\Roaming\Typora\typora-user-images\image-20240322200411557.png" alt="image-20240322200411557" style="zoom:80%;" />



##### MySQL极其常见的报错:

```mysql
https://laracasts.com/discuss/channels/laravel/incompatible-with-sql-modeonly-full-group-by

MySQL强制执行大多数其他数据库一直在执行的标准语义:
规则: 选择列表中每一列都必须是以下列之一:
	1.在group by子句中命名.
	2.在聚合函数中,如min,max,sum,group_concat();
	3.在功能上取决于分组的列
	
错误SQL:
select user_id,feature_key,feature_value from user_features
where user_id=1
group by feature_key

如果使用feature_key分组,就不符合查询列必须要在分组列中.

only_full_group_by-sql: 要求select语句中查询出来的列必须是在group by中进行声明,否则会报错.就是说,在此模式下,select target list中的值要么来自于聚合函数(sum、avg、max),要么来自于group by list中的表达式.

```

```
[执行一条 select 语句，期间发生了什么？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/mysql/base/how_select.html#mysql-执行流程是怎样的)

https://blog.admin4j.com/mysql/lin_tu_jie_mysql/#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E9%9C%80%E8%A6%81-%E4%B8%8D%E9%9C%80%E8%A6%81%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95
```



##### spark中重要角色:

```scala
Master: 一个java进程,接受worker注册信息和心跳,移除异常超时的worker、接受客户端提交的任务、负责资源调度、命令worker启动Executor.

Worker: 是一个java进程,负责管理当前节点的资源关联,向Master注册并发送心跳,负责启动Executor,并监控Executor的状态.

SparkSubmit: 是一个java进程,负责向Master提交任务.

Driver: 是很多类统称,可以认为SparkContext是Driver，client模式下Driver运行在sparkSubmit进程中,cluster模式单独运行在一个进程中,负责将用户编写的代码转换为tasks,然后调度到Executor中执行,并监控Task状态和执行进度.

Executor:负责执行Driver端生成的Task,将Task放入线程中执行.


```

<img src="C:\Users\12085\AppData\Roaming\Typora\typora-user-images\image-20240323124427505.png" alt="image-20240323124427505" style="zoom:80%;" />
